# 摘要

微观成像在材料科学中扮演着重要角色，它提供了物质的实空间信息，有助于理解材料结构与其物理或化学性质之间的相关性。不同类型的对象在不同尺度上的显微图像，检索形态、尺寸、分布、强度等有用信息是一项耗时的任务。相反，深度学习在自动提取有用信息方面展现出巨大潜力，尤其是在复杂系统的应用上。最近，研究人员利用深度学习方法进行成像分析，以识别结构并检索微观结构与性能之间的联系。在这篇综述中，我们总结了深度学习分析在显微成像应用方面的最新进展，包括扫描电子显微镜（SEM）、透射电子显微镜（TEM）和扫描探针显微镜（SPM）。我们依次介绍了深度学习的基本方法、成像分析的应用回顾以及我们对未来发展的展望。基于已发表的结果，我们提出了一个通用的深度学习分析工作流程。© 2020 Elsevier Ltd. 发布

# 1. 引言

材料科学的主要目标是揭示材料结构与其物理或化学性质之间的相关性。这里的结构指的是形态、相、原子结构、表面晶面、界面结构等。有了所谓的结构-性质相关性知识，就可以调整合成参数来控制材料的结构，从而优化新材料的应用。这是包括金属材料、半导体和用于催化、生物医学、电子、电池等功能性材料的多种材料研究的基本范式。适当的结构和性质表征方法是理解潜在相关机制至关重要的。在结构表征技术中，显微成像尤其重要，因为它可以提供大范围尺度上材料结构的实空间信息。

典型的成像工具包括光学显微镜、透射电子显微镜（TEM）、扫描电子显微镜（SEM）和扫描探针显微镜（SPM）。光学显微镜是最常见的工具，它允许我们以微米级的空间分辨率看到对象的细节。带有像差校正器的TEM提供了薄样品的空间分辨率为亚埃级的投影信息；SEM提供了表面形态（二次电子）和组成（背散射电子）的信息；SPM，包括原子力显微镜（AFM）、扫描隧道显微镜（STM）等，已被广泛用于研究原子结构和表面电子态。这些技术可以帮助识别从毫米到数十皮米的详细信息，并提供有关材料形态、相、晶体学、磁结构以及分子和原子结构的独特信息。尽管这些工具的图像具有不同的物理含义，但图像分析的过程有一些相似之处。以图1所示的TEM成像为例，分析存在四个挑战。第一个挑战是如何通过实验或模拟数据获得特定于材料的信息，或者换句话说，如何利用图像推断结构信息。第二个挑战是如何使用这些信息通过生成模型预测或生成物理和化学性质。第三个是如何重建材料行为或如何预测性能。最后一个是我们能否实现显微镜数据流的实时分析。我们相信这些挑战可以概括为任何需要从实验结果中抽象出物理知识成像技术。通常，这个工作流程是基于重复和多模态实验研究成功构建的。在一个复杂系统中，联系往往不清楚，需要时间来揭示。理想情况下，如果这种原位显微技术的知识点揭示过程可以在实时或短时间内完成，它可能极大地帮助研究人员研究系统的动态。例如，根据分析结果，研究人员可能知道如何调整实验参数或在实验期间接下来该做什么。数据驱动技术的使用，如机器学习，可以帮助完成这项任务，例如在功能材料的发现、成像表征、物理相关性质预测、材料设计等方面。此外，数据驱动技术也可以帮助提高预测和决策过程的性能。这些需求推动了近年来机器学习应用的快速增长。作为人工智能（AI）技术的一部分，机器学习已经发展和研究了几十年。它是一个计算模型和算法的研究方向，旨在使计算机系统基于数据和经验在特定任务上工作。传统的机器学习方法通常需要硬编码的特征作为输入，这些特征基本上需要人类协助设计，并且很难改变。受到大规模数据、先进的计算机算法的发展，以及计算硬件的突破，特别是图形处理单元（GPU）的兴起的启发，一种名为“深度学习”的新型表示学习方法应运而生。如图2所示，深度学习属于机器学习家族，当然也是广泛的人工智能领域。通过组合简单但非线性模块自动学习表示的能力，使深度学习比大多数传统机器学习方法更强大，后者通常需要手动选择特征提取算法作为预处理。此外，随着足够多的模块（也称为层）堆叠，深度学习可以实现复杂功能或系统。最近，深度学习在许多领域的应用加速，如社交网络分析、信息检索、语音和音频处理、视觉数据处理、自然语言处理等，如图3所列。在材料科学领域也尝试了使用深度学习方法，包括结构预测和设计、化学学习、结构-性质链接分析和结构表征等。在所有研究领域中，显微成像分析，旨在检索材料的实空间信息，尤为重要。作为不同形态主题的专注、非周期记录，图像通常包含大量信息和巨大复杂性，适合AI分析。材料科学家的一个新兴需求是了解深度学习分析如何帮助以及如何在材料数据分析中利用这个工具。在这篇综述中，我们专注于显微成像方面的深度学习研究进展。在以下文本中，我们首先介绍深度学习的概念和不同的方法模型，然后回顾深度学习在SEM、TEM、SPM等的应用。显微成像分析的进展总结如下。最后，我们在总结和展望部分阐明了利用深度学习进行图像分析的挑战和机遇。

# 2. 深度学习的概念和工作流程

首先，为了方便以下内容，我们简要介绍深度学习的基本概念。然后我们介绍显微成像分析任务的困难，通过总结显微镜图像和自然场景图像之间的差异。总之，我们提出了利用深度学习对显微成像的利用工作流程，该流程主要包含五个阶段，根据深度学习的工作方式和分析显微镜图像的需求。

## 2.1 深度学习的关键概念

图4展示了用于对象识别的神经网络的总体示意图。为了将输入图像与正确的输出标签联系起来，模型被设计为通过将其分解为简单但非线性的数学运算（如卷积、归一化、激活等）来实现复杂的识别过程。层通过传播计算信息（或特征）通过整个神经网络来连接。信息流可以通过所有堆叠的层直接进行，或者通过将当前信息和先前信息输入到当前层来递归。网络可以通过堆叠这些操作组合来实现越来越抽象和结构化的信息。例如，网络的第一层可能只提取图像中的边缘，第三层能够学习更多结构化的信息，如物体部件。通过设计和训练网络，每个简单操作可以根据优化规则的约束自动调整其参数，这些规则旨在使整个系统有效工作。在以下部分中，简要描述了几个关键概念。对于数据集，设计模型的预期结果称为“真值”（或标签），不同任务的真值数据各不相同。例如，真值可以用于分类的标记特征，而显微成像的真值可以被视为包含几何位置、半径和面积信息的分析图像。通常，数据集被分割为训练集、测试集和验证集。训练集用于使模型学习，验证集通常用于在训练期间调整超参数。测试集是模型未曾见过的数据样本，用于在训练后评估模型的性能。对于深度学习模型，如果有真值提供，则该模型称为“监督”模型，否则称为“非监督模型”。每个神经网络可以由多种类型的层组成，包括卷积层、反卷积层、激活层、池化层、全连接层、归一化层等。“特征”表示每层的隐藏表示或输出。每层表示一个数学运算，堆叠这些层可以模拟一个非常复杂的函数。例如，二维卷积运算[40]可以写成：

$$ S(i, j) = (I * K)(i, j) = \sum_m \sum_n I(i + m, j + n)K(m, n) $$

其中星号表示交叉卷积运算，I表示输入图像，K表示二维核，S表示输出特征图。ReLU，也称为修正线性单元[43]，是一种广泛使用的激活函数：

$$ g(z) = \max(0, z) $$

该函数以元素方式应用[40]。池化可以看作是采样操作，最常见的选择是最大池化，它返回采样核的最大值[40]。对于深度学习网络的优化，通常应用小批量随机方法，这些算法使用固定数量的训练样本批次来估计梯度。反向传播是训练网络的主要机制，这是一个计算每层或操作梯度的过程。当批量大小为一时，优化算法通常称为随机方法或在线方法。不同的优化方法以不同的方式从小批量中获取信息[40]。有许多高效的优化方法，如动量[44]、Adam[45]、RMSprop[46]等。所有配置，包括网络架构、优化方法和规则、训练设置，都应该仔细设计以满足任务的要求。在训练过程中，可能会发生潜在问题，如过拟合、欠拟合和梯度爆炸。过拟合是指模型学习训练数据噪声的情况，而过拟合发生在模型无法学习数据的基本趋势时。过拟合和欠拟合是偏差-方差权衡，深度学习模型的目标是平衡偏差和方差误差。通常，过拟合可以通过许多解决方案来预防，包括扩大训练集、增加正则化、提前停止训练过程、随机丢弃部分特征等。欠拟合可以通过训练更多次迭代、减少正则化和使用更复杂的模型来解决。当只有少数训练样本时，过拟合问题也可以作为表示学习问题来解决[47e49]。梯度爆炸通常出现在循环神经网络[50]中，它们通过递归连接多次使用相同的模块。梯度爆炸可以通过梯度裁剪来处理。还有许多其他潜在问题，研究人员也提出了相应的训练技巧来解决它们。预训练模型通常意味着已经使用其他数据集训练过的模型，通常是用于分类任务的Imagenet[51]数据，或用于目标检测和分割任务的COCO数据集[52]。表现良好的预训练模型，如ResNet[53]、VGG[54]、Inception Net[55e57]，在它们自己的训练数据集上可以实现出色的性能，被认为具有提取有用特征的能力。因此，预训练模型被广泛用作在其他任务中的强大且高效的特征提取器，包括语义分割（或逐像素分割）[58]、目标检测[59]等，通过在新神经网络中利用它们的架构和参数。对于模型的性能评估，通常在大多数任务中使用准确率、精确度和召回率。对于分类问题，通常使用混淆矩阵来显示结果，这是一个预测摘要。它显示了正确或错误预测结果的计数值。对于二元分类任务，混淆矩阵由四个元素组成：真正例（TP，正确预测的正值）、真负例（TN，正确预测的负值）、假正例（FP，错误预测的正值）和假负例（FN，错误预测的负值）。给定混淆矩阵，准确率、精确度和召回率可以按以下方式计算：

$$ \text{准确率} = \frac{TP + TN}{TP + TN + FP + FN} $$

$$ \text{精确度} = \frac{TP}{TP + FP} $$

$$ \text{召回率} = \frac{TP}{TP + FN} $$

准确率表示模型正确预测的比例，精确度表示所有正预测中正确的比例，召回率表示实际正例中正确预测的比例。通常，可以通过其在测试数据集上的性能来评估训练过的深度学习模型。然而，即使在测试集上准确度足够高，训练有素的模型在未见过的实例（或分布外实例）的输出中也可能存在错误。提高深度学习模型可靠性的一种方法是扩大训练数据集，专家的协助也是一种解决方案。另一种方法是估计不确定性并利用它帮助决策[60]。深度学习通常涉及大量的参数和数据，包括卷积值、激活值、梯度值等，这些都需要在训练过程的每一步中改变[40]。因此，合适的硬件和框架对于实现高效的深度学习方法至关重要。评估硬件和框架的标准不仅是计算性能，还包括能效、芯片价格、兼容性等。与CPU相比，由于高并行性和高内存带宽，GPU更广泛地被利用。更重要的是，通用GPU（GP-GPU）的发展也提供了广泛的可用性和通用性，方便的编程环境和得到良好支持的软件堆栈，以实现神经网络[61]。例如，NVIDIA的GPU由于其提出的标准库而广受欢迎，这使得深度学习方法易于建立[62]。开源框架使研究人员能够设计、实现深度学习模型，并基于现有硬件加速训练过程。有许多成熟的开源框架具有解释性语言前端。其中，像Theano、Torch、Caffe、TensorFlow、PyTorch等成熟且流行的框架，对熟悉Python或MATLAB的人来说用户友好，可以支持不同类型的硬件（无论是CPU还是GPU）并实现高性能[63]。为了说明软件配置，以ImageNet[51]数据集上的图像分类任务为例。Touvron等人提出的名为FixEfﬁcientNet的网络，在该任务上实现了88.5%的top-1得分（最高输出概率的一个目标标签的百分比，这是评估准确性得分的一种方法），参数数量为480 M，这是迄今为止使用外部数据报告的最佳网络[64]。FixEfﬁcientNet是在装有多个GPU的集群上使用PyTorch框架实现和训练的。与另一个BiT-L[65]相比，其top-1得分为87.54%，参数为928 M，FixEfﬁcientNet在参数数量和准确性方面都表现出色。除了上述的准确性和参数数量外，硬件的性能对于训练和推理的效率也至关重要。NVIDIA和ATI公司推出了许多广泛使用的产品。研究表明，它们各自在不同的应用和能效方面都有优势。例如，NVIDIA Fermi GPU在双精度问题上表现优异，而ATI Radeon GPU更具能效[66]。模型架构和硬件的配置可以直接影响模型的性能和效率。由模型结构确定的操作数量决定了推理时间。有研究表明，硬件的能源限制与准确性和模型复杂性的上限有关[67]。Bianco等人表明，在ImageNet任务上，即使是非常低复杂度的深度学习模型，仍然需要至少0.6 GB的最低GPU内存。Inception-V4模型，批量大小为1，内存消耗为0.8 GB，可以达到约80%的分类准确率，每张图像的推理时间为18.96毫秒。作为一个例子，以前的实验是基于PyTorch实现的，使用的是装有Intel Core I7-7700 CPU @ 3.60 GHz、16 GB DDR4 RAM 2400 MHz、NVIDIA Titan X Pascal GPU 12 GB内存的工作站[68]。总之，硬件部分高度依赖于深度学习模型和框架。众所周知，GPU可以加速机器学习计算，GPU的选择应该考虑模型所需的存储，以及计算和能效。需要高容量硬盘来存储大规模数据。如果数据大小超过了处理单元的可用内存，则可以分部分处理数据。对于大规模数据的存储，可以使用云存储和计算技术。

## 2.2 显微镜图像与自然图像的差异

根据FAIR指导原则[69]，科学数据应该是可查找的、可访问的、可互操作的和可重用的。重要的是开发数据分析工具，帮助管理大量的图像，并在此基础上揭示材料结构和性质之间的相关性。尽管深度学习在自然场景图像分析任务[70]上取得了巨大进步，例如目标检测、分类、预测等，自然场景分析任务与显微成像分析任务之间存在许多差异。与自然场景图像相比，材料科学的显微镜图像具有特征性特征，这使得显微成像分析任务非常不同和困难。首先，原始实验显微镜图像通常与高水平的噪声和失真相关[71,72]。有一些传统的统一图像预处理算法可以减少噪声，如高斯平滑滤波器、阶滤波器等。传统算法通常在处理高密度噪声方面存在困难，因为它们严重依赖局部信息。

然而，深度学习算法可以通过明确定义的真值和模型架构克服噪声的限制[39]。其次，显微镜图像数据集通常是灰度的，与自然场景图像不同。自然场景图像大多是彩色的（红色、绿色、蓝色（RGB）或带有另一个深度通道的RGBD），并且具有丰富的自然纹理。为了增加数据集的数量和多样性，增强对于有限数据的情况至关重要，包括几何变换、颜色空间增强、核滤波器等[73]。最近一些使用深度学习进行显微成像分析的工作通过简单的变换如旋转[74,75]来增强训练数据集，以丰富训练数据集并避免过拟合。此外，大多数原子分辨图像具有晶格的唯一周期性，表征方法应该遵循原子的分布。第三，显微镜图像的信息与物理或化学约束和实验环境有很强的关联，这使得显微镜图像数据集的结构更加复杂。每个显微镜图像都有特定的物理和化学参数，包括材料类型、成像技术、设备参数、环境因素等。更重要的是，显微镜图像通常具有非常高的分辨率。因此，显微镜数据的规模更大，每个数据节点的结构比自然场景图像数据更复杂。显微镜数据集的复杂性和多样性使得通过人为努力发现材料特定的指纹非常困难。然而，深度学习方法擅长处理和挖掘大规模数据集，这决定了它们适应大规模显微成像数据的能力。第四，分析任务通常需要在动态数据集或“电影”上完成，以便观察材料转化的过程。像长短期记忆（LSTM）网络[76]这样的深度学习模型可以“记住”信息很长一段时间，并且已经在几个任务中广泛应用，包括自然语言处理（NLP）[17]、交通预测[77]、人类行为识别[78]等。利用时空神经网络可以帮助定位和分析材料的动态过程。此外，最大的挑战可能是难以实现的“真值”标签。对于监督任务，需要标记数据（真值）。通常，真值可以通过人工研究人员和计算机模拟获得，这既耗时又低效。此外，监督深度学习模型的训练和实验的验证或分析需要大量准确标记的数据。上述因素使得真值的生成非常重要和具有挑战性。有一些工作使用人工辅助标记的数据[75,79]。许多算法使用模拟数据[80e83]、预先处理过的数据[39,84]。一种方法是使用软件或理论模型生成可靠的模拟数据集，考虑影响生成结果的多种物理和化学因素的变异。另一种方法是考虑使用少样本学习方法[85]，这些方法旨在解决用非常小的训练集向深度学习模型提供数据的问题。最后，许多显微成像任务不是完全确定性的，需要进一步的分析或解释。与大多数自然场景或语言处理任务不同，它们有明确和明确的知识作为基础，材料科学中的许多现象是意想不到的或不可预见的，需要科学家对它们的原因和知识进行进一步研究。考虑到上述所有特征，深度学习在材料科学显微成像方面的研究应该在物理和化学约束和知识的指导下进行仔细设计和实施。

## 2.3 使用深度学习进行显微镜图像分析的工作流程

工作流程可以总结为图5所示的过程，包含五个阶段，包括任务分析、数据准备、模型设计、特征分析和验证。第一步是任务规范和分析，包括确定任务类别、物理约束和其他要求。例如，表征或量化任务可以被描述为确定性问题，另一方面，链接学习任务可以作为回归问题呈现。第二步是通过人工辅助或模拟工具准备数据集。如果学习任务是监督的，那么数据集应该包含标签，或者换句话说，输入数据的预期结果。第三步是根据任务和现有数据设计模型。接下来是特征分析，它有助于从训练模型的输出中以材料科学的角度提取模式。最后是验证和进一步分析，以对属性或性能进行预测，验证假设或观察特定现象。利用深度学习的整体目标是模拟实验数据与相应属性之间的联系，然后使用该联系来重建或预测性能。

# 3. 深度学习在显微镜成像分析中的应用

在这里，我们回顾了最近发布的关于扫描电子显微镜（SEM）、透射电子显微镜（TEM）/扫描透射电子显微镜（STEM）和扫描探针显微镜（SPM）技术图像分析的报告。

## 3.1 SEM图像分析

深度学习已被用于解决两个SEM图像分析问题：一个是基于形态特征对SEM图像进行分类[38,79,86]，另一个是分辨率增强以提高图像质量[87]。Modarres等人使用预训练的深度学习模型对SEM图像进行分类，如图6和表1[79]所示。作者比较了四种不同的深度学习模型（Inception-slim、Inception-v3、Inception-v4和ResNet）的结果，并证明了Inception-v3[56]在准确性和计算效率方面优于其他模型。该模型由对称和不对称块组成，包括卷积、池化（或下采样）、连接等。作者手动标记了18,577张图像为10个类别作为训练集。表1显示了算法在总共1,853张图像的测试集上的分类准确性。测试集的结果表明，对于具有不同图像特征的类别，如图案化表面和微电子机械系统（MEMS）设备，神经网络无法实现良好的性能。在进行了更详细的类别设置的更深入分析的数据集上，大多数子类别都被正确标记。另一个案例是对低碳钢图像进行逐像素分类[38,86,88,89]。逐像素分类是一种通过为图像中的每个像素分配特定标签来进行分类的方法，与上述全局图像分类相比，它具有提供对象形状和区域详细信息的优势。Azimi等人提出了一种基于对象的卷积神经网络，用于对成分和相进行分类，如图7[86]所示。开发了一个名为最大投票全卷积神经网络（FCNN）[MVFCNN]的网络，用于对低碳钢SEM或光学显微镜（LOM）图像进行逐像素分割。通过比较基于对象和逐像素分类网络，作者得出结论，后者产生了更准确和详细的分割结果，在其中清晰区分了马氏体、回火马氏体、贝氏体、珠光体和背景的特征。也有关于超低碳钢微观结构的逐像素分类的报告[3888,89]。DeCost等人从SEM成像结果中开发了一个名为超低碳钢数据库（UHCSDB）的数据集以及该数据集的处理和可视化工具[88,89]。基于该数据集和一个名为PixelNet[90]的网络，该网络使用来自多个尺度的卷积结果作为最终特征图，DeCost等人对包括前共析晶界碳化物、铁素体基体、球状颗粒、Widmanst€atten碳化物在内的小微观成分进行了分割和分析，如图8[38]所示。这些案例表明，一个适当设计和训练的网络可以有效地对大量数据进行物理特征分类。最终的分类结果可以从图像的全局类别到小颗粒表征，通过使用选定的网络、准备的真值和对目标的先验知识来实现。深度学习方法被应用于提高SEM图像的分辨率，这有助于检索对聚焦电子束敏感的样品的有用特征，如图9[87]所示。生成对抗网络（GANs）[91]被用于这项任务，它们基于博弈论的理念开发，通常包括两个分支网络，即生成器和鉴别器。在图像增强的情况下，生成器旨在从低分辨率重建高分辨率图像，鉴别器被训练来区分哪些是生成图像或假图像。当鉴别器无法区分时，生成器成功地学会了如何尽可能真实地进行预测。本研究中使用的训练数据集是基于金-碳样品构建的，低分辨率和高分辨率图像在不同的放大倍数下拍摄。分析显示了训练模型在提高SEM图像质量方面的能力，分辨率提高了两倍。图像增强的成功证明了深度学习具有从有限信息预测显微数据的能力。

## 3.2 STEM图像分析

扫描透射电子显微镜（STEM）成像技术具有独特的材料科学能力：（1）高角环形暗场（HAADF）-STEM可以提供原子序数对比（Z对比）成像，其中可以直接从对比中区分元素。（2）STEM成像具有更好的空间分辨率，由电子束斑大小决定，可以小到亚埃级。因此，STEM已被广泛用于收集晶体结构和缺陷的实空间信息[74,80e84,92e95]。深度学习的神经网络能够更有效地探索晶体学相、原子构型和动态转变。STEM成像分析的目标是表征原子结构、缺陷性质以及样品的形态，并将结构信息与材料特定的属性和性能相关联，如图1所示。晶体学缺陷可以使用深度学习框架进行分割[74]，如图10所示。Roberts等人提出了一个名为DefectSegNet的网络，用于在先进的衍射对比成像（DCI）STEM图像中逐像素检测和分类晶体学缺陷为三类，包括位错线、沉淀物和空隙。DefectSegNet的设计灵感来自UNet[96]和DenseNet[97]，前者在生物医学分割中表现出色，后者通过创建从早期层到后期层的短路径，实现了对所有卷积层的充分利用。该网络使用200 kV、会聚半角6.2 mrad和明场收集角9 mrad的JEOL ARM200CF显微镜获得的高质量DCI STEM缺陷图像对HT-9马氏体钢进行了训练，比较证明，基于深度学习的语义分割在像素精度和时间效率方面优于人类专家的缺陷量化。原子分辨STEM图像的分析通常遵循图5的工作流程。在任务分析之后，人们可能会准备通过手动标记或基于样品原子结构的模拟生成的数据集。模拟的STEM图像可以提供包含我们感兴趣特征的准确真值，这可以通过使用一些成像模拟软件来完成，如JEMS或Crystal Maker等。使用模拟图像非常高效，但它们有局限性，因为这些图像不包含真实情况的特征，如噪声、扫描失真、应变效应和其他因素。而研究人员标记的实验图像可能更加真实可靠，但耗时。如图11所示，给定一个适当训练的网络，可以提取结构信息，如原子位置[82]、哑铃状原子[93]、原子的柱高[80]、晶格类型[81]和缺陷类型[84]。例如，Ziatdinov等人使用了一个高效的“原子发现”工具，通过结合深度学习网络和图像处理算法来识别原子位置[82,93]。训练的网络输出每个像素是原子列还是背景的概率。然后使用高斯拉普拉斯blob检测用于提取每个圆形原子的中心[82]，椭圆拟合方法用于识别哑铃状原子[93]。此外，根据检测到的原子，可以使用图表示来表征三配位和四配位硅原子[82]。通过深度学习模型提取的结构信息，可以根据获得的材料特定信息和某些材料的先验知识进一步推导出模式和配置。更重要的是，还可以构建缺陷库[95]，以帮助研究材料的功能。Maksov等人对动态STEM成像中分层WS2的缺陷结构和相演变进行了无监督分类和分析[84]。如图12所示，作者用电子束辐照下掺杂Mo的WS2的运动的第一帧电影训练了一个神经网络，以检测缺陷，然后，同一组使用高斯混合模型（GMM）沿着空间和时间维度，将所有缺陷聚类为五组，区分并提供了这些不同缺陷轨迹的可视化。其中，与Mo掺杂剂相关的两种缺陷类型显示出奇特的切换行为，它们通过使用原子发现器和主成分分析（PCA）分析内部结构来提取对称性畸变。这两种缺陷类型随后被分类为四个子类，包括未畸变的Mow缺陷和三个（Mow + Vs）复合体。这四个子类的转移矩阵表明Mow缺陷可能与S空位相关联，Mo掺杂剂可能捕获在电子束辐照期间在附近产生的S空位。在这项工作中，作者表明他们能够识别主导的点缺陷，分析所选缺陷物种的扩散，并且还研究了转变路径。Ziatdinov等人使用类似的方法研究了石墨烯中单个Si原子的运动，并观察到在电子束操作下SieC缺陷构型的对称性破缺[92]。如图13所示，作者使用聚焦STEM电子束分别沿预定的圆形和线性轨迹激活Si掺杂原子。开发了一个深度卷积网络，用包含3,000个模拟图像的训练数据集重建晶格或杂质原子。从提取的原子位置，重建了晶格的分布，并根据统计直方图对键长进行了聚类。从Si原子位置和键长的分析中，作者发现，掺杂原子附近的键长变化在10%以下，这表明与掺杂原子的运动没有显著的键畸变。然而，通过进一步分析时间序列中三配位SieC键长的分布，观察到了对称性破缺，这可能与样品的更大倾斜有关。如图14所示，深度学习方法也可以用来描述电子束辐照下石墨烯边缘和体相中Si原子的动力学和热力学[94]。在这种情况下，训练了一个网络来表征所有原子，特别是位于纳米孔边缘的原子。然后，将Si杂质周围的局部构型裁剪并聚类为状态描述符，进一步提供了不同状态之间转换概率的视图。作者最终确定了石墨烯纳米孔边缘上1D有序Si结构的稳定性以及Si杂质与体相中拓扑晶格重构的耦合。深度学习的另一个应用是通过2D环形亮场（ABF）图像推断原子的3D旋转畸变[83]，如图15所示。以前提取3D局部信息的方法是通过分析ABF显微图像中的柱形形状由人类专家检查和定量3D八面体旋转信息[98]，它们的性能受到手动识别的柱形形状的限制。为了解决传统方法的限制，Laanait等人使用三个角度来表示所有旋转，并训练了一个12层的卷积网络，使用面向[110]投影的原型钙钛矿SrTiO3的模拟数据集，以检测氧化物钙钛矿材料的原子畸变。训练有素的神经网络在提取实验数据的对称性和八面体旋转幅度方面表现出色，并且很好地推广到了与训练数据不同的化学组成，包括CaTiO3、La0.7Sr0.3MnO3、(LaAlO3)0.3(Sr2AlTaO6)0.7和Eu0.7Sr0.3MnO3。在上述案例中，深度学习在提取传统计算机引导分析方法难以处理的底层信息方面展现出巨大的能力。

## 3.3 SPM图像分析

扫描探针显微镜（SPM）是一类用于成像表面从纳米到毫米区域的工具[4]。为了形成图像，扫描探针显微镜扫描其尖端在表面上，并以恒定的互动模式或恒定高度模式检测电子反馈信号。常见的SPM方法包括扫描隧道显微镜（STM）、原子力显微镜（AFM）等。事实上，许多基于STEM数据集衍生的深度学习方法也可以推广到SPM数据的任务[81,82,93]，这可能是深度学习在图像分析能力上的另一个证据。众所周知，SPM尖端的大小对于SPM图像的质量和空间分辨率至关重要。误用的尖端可能会在最终图像上产生伪影[99]。一个应用是自动尖端修整在SPM图像上，主要是在氢终止的（100）硅基底上[75]，如图16所示。原位尖端调节技术对于原子尺度的表征和操纵很重要。因此，Rashidi等人提出了一个神经网络，该网络用大约3,500张硅悬挂键的STM图像进行训练，自动尖端修整可以达到99%的准确率。另一个应用是表面分子结构和旋转状态的识别与分类[100]，如图17所示。通过结合马尔可夫网络和卷积神经网络，该框架可以识别每个分子是碗向上还是碗向下状态，并将旋转分类为四类。神经网络在合成STM图像上进行训练，这些图像是使用以电子电荷密度分布的密度泛函理论计算为输入的马尔可夫链蒙特卡洛采样器生成的。训练好的模型还在金（111）上的巴基球实验STM数据上进行了测试。通过分析所有分子状态的成对分布，可以观察到碗向上/向下状态的切换与倒置分子中旋转无序的形成之间的关联。通过探索输出局部相关性，还分析了碗反转的“两阶段”反应路径及其对邻近分子的影响。研究表明，神经网络使发现隐藏属性更加高效。神经网络还可以帮助建立热力学条件与STM图像之间的联系。Vlcek等人开发了一个框架，用于分析La1-xCaxMnO3 (LCMO)薄膜中的元素偏聚[101]，如图18所示。作者首先提出了一个平衡系统的统计模型，该模型只包含三个可调变量，以预测给定STM图像和X射线光电子能谱（XPS）结果的3D结构：

$$u_i = w_{CL} \sum_{f_{CL}} d_{b,CL}^i + w_{LL} \sum_{f_{L,L}} d_{s,LL} + w_{LO} \sum_{f_{L,O}} d_{s,LO} $$

其中Ca^2+和La^3+表示金属阳离子，O表示表面氧。指标b和s表示至少一个原子属于体相（b）或两者都属于表面层（s），d_XY为1时粒子是X或Y，否则为0。三个变量w_CL、w_LL、w_LO表示Ca^2+和La^3+阳离子在体相中的最近邻对之间的相互作用能，在表面未被表面氧屏蔽的La^3+阳离子之间的最近邻和次近邻对之间的相互作用能，以及La^3+与最近表面之间的相互作用能。学习到的参数以约化单位给出：(w = w / k_B T) w_CL = 0.194; w_LL = 0.739; w_LO = -0.890，可以从弹性和静电有效相互作用的角度进行解释。有了这些参数，就可以通过规范的蒙特卡洛方法生成3D微观结构。基于优化的统计模型，可以使用称为变分自编码器（VAE）[102]的生成模型探索结构配置与热力学条件（如温度或化学势）之间的联系。VAE能够将原子构型编码为少数几个潜在参数，并且可以观察到编码的潜在参数与温度和组成之间的关系。当Ca浓度值为0.5时，实验结果表明潜在参数、温度和组成之间存在明显的趋势，表明在0.5表面化学计量时存在熵稳定。通过模拟和探索材料属性与实验条件之间的联系，神经网络可能有助于设计特殊需求材料的过程。

# 4. 总结和展望

在这篇综述中，我们总结了深度学习在各种显微成像分析中的应用。基于已发表的报告，我们提出了一个通用的深度学习成像分析工作流程，包括特定任务分析、工作准备、模型设计、特征分析和验证。到目前为止，深度学习的应用主要集中在提取结构信息，如形态、相、缺陷的识别和跟踪等。此外，生成模型也被一些工作使用，包括超分辨率重建和实验条件与微观结构之间的联系构建。生成模型[91,102]是强大的工具，可以模拟输入和输出之间的联系，并且还可以有助于降维，这在理论计算中可能很有用。展望未来，利用深度学习方法进行显微成像分析的兴起将带来挑战和机遇。如上所述，大多数现有工作使用了类似的模型和架构，通常是由卷积层、归一化层和激活层堆叠而成的自动编码器。随着深度学习应用的蓬勃发展，还有其他强大的算法，如长短期记忆（LSTM）[76]或图神经网络（GNN）[103]，用于解决材料研究数据的复杂数据结构。数据科学家和材料科学家或显微学家必须共同努力，将深度学习工具应用于解决材料问题，这意味着双方都必须学习知识或代码、范式或架构以及其他领域的语言。这将是一个痛苦的、具有挑战性的，但令人兴奋的智力旅程。我们希望我们之前的综述能够为深度学习的背景提供一些提示。对于显微学家来说，掌握一些流行的软件并将其用于一些问题是一个很好的开始。另一方面，深度学习专家的重要任务是开发用户友好的软件/平台，并为显微学家提供所需的培训。这些软件/平台应该足够专业化于某些材料主题，并且足够通用于具有不同实验条件的图像。深度学习承诺能够高效地从大量数据中检索隐藏信息。原位TEM能够记录结构变化作为时间的函数，并生成比原位TEM工作多3-4个数量级的数据[2,104e108]。由于这种迫切的需求，包括深度学习在内的AI技术将在未来迅速发展并应用于原位TEM。深度学习方法也已应用于倒空间中的晶体学分析，例如，从电子衍射自动分类晶体结构[109]，自动分析汇聚束电子衍射图案[110111]以及锂离子导体中特定的结构-性能相关性[6]。由于电子晶体学和显微分析之间的物理相关性，这两种不同主题的深度学习分析也可以相互关联，以揭示材料的完整结构-性能场景。由于篇幅有限，这篇综述没有包括深度学习在基于X射线的显微成像技术[112]中的应用。深度学习工具已被广泛用于医学科学中的X射线技术，这些技术已被广泛回顾。尽管深度学习在大数据时代特别强大，因为它能够学习识别模式并从复杂数据中提取结构，但我们需要注意实际情况中的操作。首先，模型和损失函数的设计应该反映基本的物理和化学原理，就像一些前沿研究在计算机科学和物理科学关系方面的工作一样[113]。先验知识对于有意义的分析是必要的。从训练模型获得的配置应始终与其他已确认的物理约束的结果进行比较。其次，模型应该用测试案例运行，这有助于我们判断有效性。换句话说，为网络训练生成有意义的真值是必要的。如第2.2节所述，人工标记数据耗时，而且本综述中提到的大多数训练数据集是通过模拟生成的。然而，模拟数据通常是人为案例，与真实主题存在一定的差异。需要特别注意使神经网络适应真实的实验数据。随着不同实验室在该领域收集的越来越多的数据，有可能将成像数据整合到数据库中，并希望进一步检索信息。深度学习在生物学和医学图像处理中的成功应用鼓励了深度学习在显微成像处理中的发展，这可能真正推进材料科学领域。此外，可以根据从深度学习模型获得的信息设计和实施受控实验，以验证训练模型或发现特定相关性。作为一个新兴领域，材料信息学已被提出，旨在超越传统材料设计和发现的范式[114,115]。与在生物学、药物发现、天文学等领域建立的信息学概念类似，材料信息学是信息科学与材料科学的结合，并承诺加速材料研究。例如，在电池领域已经建立了几个从头算数据库，为材料探索提供理论指导[116,117]。作为材料信息学研究循环中的基本技术，深度学习分析在处理大量实验结果方面具有独特的能力，并将在未来在材料科学中变得越来越重要。

声明：作者声明他们没有可能影响本文报告工作的任何已知的财务利益或个人关系。

致谢：本工作得到中国国家自然科学基金（U1931202, 61532018）和北京市科学技术委员会科学技术基金的支持。